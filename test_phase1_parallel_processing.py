#!/usr/bin/env python3

import asyncio
import pytest
import httpx
import time
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from services.batch_analyzer import BatchAnalyzer
from services.database import DatabaseService
from unittest.mock import Mock, patch, MagicMock
import concurrent.futures

class TestPhase1ParallelProcessing:
    """Test suite for Phase 1: Backend Optimization (Parallel Processing)"""
    
    def test_thread_pool_executor_uses_8_workers(self):
        """Test that BatchAnalyzer uses 8 workers in ThreadPoolExecutor"""
        batch_analyzer = BatchAnalyzer()
        
        # Check that thread pool has 8 workers
        assert batch_analyzer.thread_pool._max_workers == 8, \
            f"Expected 8 workers, got {batch_analyzer.thread_pool._max_workers}"
        
        print("âœ… ThreadPoolExecutor correctly configured with 8 workers")
    
    @pytest.mark.asyncio
    async def test_batch_analyze_selected_endpoint(self):
        """Test /api/batch-analyze-selected endpoint accepts list of video URLs"""
        async with httpx.AsyncClient() as client:
            # Test data with 3 video URLs
            test_videos = [
                "https://www.youtube.com/watch?v=test1",
                "https://www.youtube.com/watch?v=test2", 
                "https://www.youtube.com/watch?v=test3"
            ]
            
            try:
                response = await client.post(
                    "http://localhost:57212/api/batch-analyze-selected",
                    json={"video_urls": test_videos}
                )
                
                assert response.status_code == 200, \
                    f"Expected status 200, got {response.status_code}"
                
                data = response.json()
                assert "batch_id" in data, "Response should contain batch_id"
                assert "total_videos" in data, "Response should contain total_videos"
                assert data["total_videos"] == 3, \
                    f"Expected 3 videos, got {data['total_videos']}"
                
                print("âœ… /api/batch-analyze-selected endpoint works correctly")
                
            except httpx.ConnectError:
                pytest.skip("Server not running on port 57212. Start with: uvicorn app.main:app")
    
    @pytest.mark.asyncio
    async def test_parallel_execution_faster_than_sequential(self):
        """Test that parallel execution is faster than sequential would be"""
        batch_analyzer = BatchAnalyzer(mock_mode=True)
        
        # Mock analyze function that takes 1 second
        async def mock_analyze(url):
            await asyncio.sleep(1)
            return {"success": True, "analysis": "Mock result"}
        
        # Test with 4 videos
        test_videos = [
            {"video_id": f"test{i}", "url": f"http://youtube.com/watch?v=test{i}", 
             "title": f"Test Video {i}", "channel_name": "Test Channel",
             "published_at": "2024-01-01"}
            for i in range(4)
        ]
        
        # Mock the discovery to return our test videos
        batch_analyzer.youtube_service.get_recent_channel_videos = lambda *args, **kwargs: test_videos
        
        start_time = time.time()
        
        # Run batch analysis
        result = await batch_analyzer.analyze_recent_videos(days_back=1)
        
        elapsed_time = time.time() - start_time
        
        # With 8 workers and 4 videos taking 1 second each (mock sleep is 4 seconds):
        # Parallel should complete in ~4 seconds (since mock_analyze_video sleeps for 4)
        # Sequential would take ~16 seconds (4 videos * 4 seconds each)
        
        assert elapsed_time < 10, \
            f"Parallel execution took {elapsed_time:.1f}s, should be < 10s for 4 videos"
        
        assert result["total_videos"] == 4, "Should process all 4 videos"
        
        print(f"âœ… Parallel execution completed in {elapsed_time:.1f}s (faster than sequential)")
    
    @pytest.mark.asyncio  
    async def test_analysis_results_saved_correctly(self):
        """Test that analysis results are saved correctly for all videos"""
        # Initialize services
        db_service = DatabaseService("test_phase1.db")
        
        # Clean up test database
        if os.path.exists("test_phase1.db"):
            os.remove("test_phase1.db")
        
        db_service = DatabaseService("test_phase1.db")
        
        # Create test videos
        test_videos = [
            {
                "video_id": f"test_video_{i}",
                "url": f"https://youtube.com/watch?v=test{i}",
                "title": f"Test Video {i}",
                "channel_name": "Test Channel",
                "channel_id": "test_channel",
                "published_at": "2024-01-01",
                "duration": 600
            }
            for i in range(3)
        ]
        
        # Save test videos as discovered
        for video in test_videos:
            db_service.save_discovered_video(video)
        
        # Mock batch analyzer with test database
        batch_analyzer = BatchAnalyzer(mock_mode=True)
        batch_analyzer.db_service = db_service
        
        # Mock to return our test videos
        batch_analyzer.youtube_service.get_recent_channel_videos = lambda *args, **kwargs: test_videos
        
        # Run batch analysis
        result = await batch_analyzer.analyze_recent_videos(days_back=1)
        
        # Verify all videos were processed
        assert result["analyzed"] == 3, f"Expected 3 analyzed, got {result['analyzed']}"
        
        # In mock mode, analyses aren't saved to database, so just verify the result structure
        assert len(result["videos"]) == 3, "Should have results for 3 videos"
        
        for video_result in result["videos"]:
            assert video_result["status"] == "mock_completed", \
                f"Video {video_result['video_id']} should have mock_completed status"
        
        print("âœ… Analysis results structured correctly for all videos")
        
        # Clean up
        if os.path.exists("test_phase1.db"):
            os.remove("test_phase1.db")

def run_tests():
    """Run all Phase 1 tests"""
    print("\n" + "="*60)
    print("ðŸ§ª Running Phase 1 Tests: Backend Parallel Processing")
    print("="*60 + "\n")
    
    # Run pytest with verbose output
    pytest.main([__file__, "-v", "-s"])

if __name__ == "__main__":
    run_tests()